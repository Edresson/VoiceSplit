{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a noteboook used to generate the speaker embeddings with the  GE2E model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'GE2E-Speaker-Encoder' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "# Clone encoder \n",
    "#!git clone https://github.com/CorentinJ/Real-Time-Voice-Cloning.git\n",
    "! git clone https://github.com/Edresson/GE2E-Speaker-Encoder.git\n",
    "os.chdir('GE2E-Speaker-Encoder/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install voxceleb_trainer Requeriments\n",
    "!python -m pip install umap-learn visdom webrtcvad librosa>=0.5.1 matplotlib>=2.0.2 numpy>=1.14.0  scipy>=1.0.0  tqdm sounddevice Unidecode inflect multiprocess numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  pretrained.zip\n",
      "   creating: encoder/saved_models/\n",
      "  inflating: encoder/saved_models/pretrained.pt  \n",
      "   creating: synthesizer/\n",
      "   creating: synthesizer/saved_models/\n",
      "   creating: synthesizer/saved_models/logs-pretrained/\n",
      "   creating: synthesizer/saved_models/logs-pretrained/taco_pretrained/\n",
      " extracting: synthesizer/saved_models/logs-pretrained/taco_pretrained/checkpoint  \n",
      "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.data-00000-of-00001  \n",
      "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.index  \n",
      "  inflating: synthesizer/saved_models/logs-pretrained/taco_pretrained/tacotron_model.ckpt-278000.meta  \n",
      "   creating: vocoder/\n",
      "   creating: vocoder/saved_models/\n",
      "   creating: vocoder/saved_models/pretrained/\n",
      "  inflating: vocoder/saved_models/pretrained/pretrained.pt  \n"
     ]
    }
   ],
   "source": [
    "#Download encoder Checkpoint\n",
    "!wget https://github.com/Edresson/Real-Time-Voice-Cloning/releases/download/checkpoints/pretrained.zip\n",
    "!unzip pretrained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from encoder import inference as encoder\n",
    "from encoder.params_model import model_embedding_size as speaker_embedding_size\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the encoder, the synthesizer and the vocoder...\n",
      "Loaded encoder \"pretrained.pt\" trained to step 1564501\n",
      "Testing your configuration with small inputs.\n",
      "\tTesting the encoder...\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing the encoder, the synthesizer and the vocoder...\")\n",
    "encoder.load_model(Path('encoder/saved_models/pretrained.pt'))\n",
    "print(\"Testing your configuration with small inputs.\")\n",
    "# Forward an audio waveform of zeroes that lasts 1 second. Notice how we can get the encoder's\n",
    "# sampling rate, which may differ.\n",
    "# If you're unfamiliar with digital audio, know that it is encoded as an array of floats \n",
    "# (or sometimes integers, but mostly floats in this projects) ranging from -1 to 1.\n",
    "# The sampling rate is the number of values (samples) recorded per second, it is set to\n",
    "# 16000 for the encoder. Creating an array of length <sampling_rate> will always correspond \n",
    "# to an audio of 1 second.\n",
    "print(\"\\tTesting the encoder...\")\n",
    "\n",
    "wav = np.zeros(encoder.sampling_rate)    \n",
    "embed = encoder.embed_utterance(wav)\n",
    "print(embed.shape)\n",
    "\n",
    "# Embeddings are L2-normalized (this isn't important here, but if you want to make your own \n",
    "# embeddings it will be).\n",
    "#embed /= np.linalg.norm(embed) # for random embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GE2E-CorentinJ-ExtractSpeakerEmbeddings-by-sample.ipynb\r\n",
      "GE2E-Speaker-Encoder\r\n",
      "Speech2Phone-ExtractSpeakerEmbeddings-by-sample.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "! ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constants\n",
    "DATA_ROOT_PATH = '../../../../LibriSpeech/voicefilter_data/'\n",
    "TRAIN_DATA = os.path.join(DATA_ROOT_PATH, 'train')\n",
    "TEST_DATA = os.path.join(DATA_ROOT_PATH, 'test')\n",
    "glob_re_wav_emb = '*-ref_emb.wav'\n",
    "glob_re_emb = '*-emb.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000152-ref_emb.wav',\n",
       " '000152-mixed.wav',\n",
       " '000131-target.wav',\n",
       " '000107-ref_emb.wav',\n",
       " '000063-mixed.wav',\n",
       " '000070-mixed.wav',\n",
       " '000159-ref_emb.wav',\n",
       " '000048-target.wav',\n",
       " '000048-ref_emb.wav',\n",
       " '000030-mixed.wav',\n",
       " '000149-mixed.wav',\n",
       " '000065-mixed.wav',\n",
       " '000094-mixed.wav',\n",
       " '000156-mixed.wav',\n",
       " '000107-mixed.wav',\n",
       " '000110-target.wav',\n",
       " '000087-target.wav',\n",
       " '000157-target.wav',\n",
       " '000055-ref_emb.wav',\n",
       " '000126-target.wav',\n",
       " '000065-ref_emb.wav',\n",
       " '000158-target.wav',\n",
       " '000025-mixed.wav',\n",
       " '000121-ref_emb.wav',\n",
       " '000083-ref_emb.wav',\n",
       " '000094-target.wav',\n",
       " '000015-target.wav',\n",
       " '000055-target.wav',\n",
       " '000123-ref_emb.wav',\n",
       " '000148-mixed.wav',\n",
       " '000024-target.wav',\n",
       " '000025-ref_emb.wav',\n",
       " '000063-ref_emb.wav',\n",
       " '000048-mixed.wav',\n",
       " '000126-mixed.wav',\n",
       " '000018-mixed.wav',\n",
       " '000123-mixed.wav',\n",
       " '000087-mixed.wav',\n",
       " '000110-ref_emb.wav',\n",
       " '000157-ref_emb.wav',\n",
       " '000149-ref_emb.wav',\n",
       " '000157-mixed.wav',\n",
       " '000077-ref_emb.wav',\n",
       " '000077-mixed.wav',\n",
       " '000148-target.wav',\n",
       " '000030-target.wav',\n",
       " '000121-target.wav',\n",
       " '000055-mixed.wav',\n",
       " '000030-ref_emb.wav',\n",
       " '000021-ref_emb.wav',\n",
       " '000156-target.wav',\n",
       " '000159-mixed.wav',\n",
       " '000156-ref_emb.wav',\n",
       " '000085-ref_emb.wav',\n",
       " '000065-target.wav',\n",
       " '000085-target.wav',\n",
       " '000107-target.wav',\n",
       " '000051-mixed.wav',\n",
       " '000021-target.wav',\n",
       " '000070-target.wav',\n",
       " '000061-mixed.wav',\n",
       " '000025-target.wav',\n",
       " '000033-ref_emb.wav',\n",
       " '000001-mixed.wav',\n",
       " '000000-ref_emb.wav',\n",
       " '000046-target.wav',\n",
       " '000158-ref_emb.wav',\n",
       " '000033-mixed.wav',\n",
       " '000083-target.wav',\n",
       " '000110-mixed.wav',\n",
       " '000123-target.wav',\n",
       " '000017-ref_emb.wav',\n",
       " '000001-ref_emb.wav',\n",
       " '000063-target.wav',\n",
       " '000158-mixed.wav',\n",
       " '000024-ref_emb.wav',\n",
       " '000094-ref_emb.wav',\n",
       " '000018-target.wav',\n",
       " '000017-target.wav',\n",
       " '000017-mixed.wav',\n",
       " '000070-ref_emb.wav',\n",
       " '000046-ref_emb.wav',\n",
       " '000051-target.wav',\n",
       " '000159-target.wav',\n",
       " '000018-ref_emb.wav',\n",
       " '000077-target.wav',\n",
       " '000131-mixed.wav',\n",
       " '000061-ref_emb.wav',\n",
       " '000126-ref_emb.wav',\n",
       " '000148-ref_emb.wav',\n",
       " '000152-target.wav',\n",
       " '000033-target.wav',\n",
       " '000121-mixed.wav',\n",
       " '000046-mixed.wav',\n",
       " '000083-mixed.wav',\n",
       " '000024-mixed.wav',\n",
       " '000149-target.wav',\n",
       " '000021-mixed.wav',\n",
       " '000015-mixed.wav',\n",
       " '000000-target.wav',\n",
       " '000015-ref_emb.wav',\n",
       " '000131-ref_emb.wav',\n",
       " '000087-ref_emb.wav',\n",
       " '000061-target.wav',\n",
       " '000051-ref_emb.wav',\n",
       " '000001-target.wav',\n",
       " '000000-mixed.wav',\n",
       " '000085-mixed.wav']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(TEST_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 36/36 [00:10<00:00,  3.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#Preprocess dataset\n",
    "train_files = sorted(glob(os.path.join(TRAIN_DATA, glob_re_wav_emb)))\n",
    "test_files = sorted(glob(os.path.join(TEST_DATA, glob_re_wav_emb)))\n",
    "\n",
    "if len(train_files) == 0 or len(test_files):\n",
    "    print(\"check train and test path files not in directory\")\n",
    "files  = train_files+test_files\n",
    "      \n",
    "\n",
    "for i in tqdm(range(len(files))):\n",
    "    wave_file_path = files[i]\n",
    "    wav_file_name = os.path.basename(wave_file_path)\n",
    "    # Extract Embedding\n",
    "    preprocessed_wav = encoder.preprocess_wav(wave_file_path)\n",
    "    file_embedding = encoder.embed_utterance(preprocessed_wav)\n",
    "    output_name = wave_file_path.replace(glob_re_wav_emb.replace('*',''),'')+glob_re_emb.replace('*','')\n",
    "    torch.save(torch.from_numpy(file_embedding.reshape(-1)), output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=0.5.1\t     encoder\t\t    requirements.txt\r\n",
      "=1.0.0\t     encoder_preprocess.py  synthesizer\r\n",
      "=1.14.0      encoder_train.py\t    synthesizer_preprocess_audio.py\r\n",
      "=2.0.2\t     pretrained.zip\t    vocoder\r\n",
      "demo_cli.py  README.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
